services:
  pihole:
    container_name: pihole
    image: pihole/pihole:latest
    hostname: pihole
    networks:
      macvlan:
        ipv4_address: 192.168.254.1
    environment:
      TZ: "America/New_York"
      FTLCONF_webserver_api_password: ${PIHOLE_UI_PASSWORD}
      FTLCONF_dns_listeningMode: "all"
      FTLCONF_dns_upstreams: "192.168.254.253"
      FTLCONF_dhcp_active: "true"
      FTLCONF_dhcp_start: "192.168.0.51"
      FTLCONF_dhcp_end: "192.168.253.254"
      FTLCONF_dhcp_router: "192.168.0.1"
      FTLCONF_dhcp_leaseTime: "24h"
      FTLCONF_dhcp_ipv6: "true"
    volumes:
      - "./pihole:/etc/pihole"
      #- './etc-dnsmasq.d:/etc/dnsmasq.d'
    cap_add:
      - NET_ADMIN
      - SYS_TIME
      - SYS_NICE
    restart: unless-stopped
  # 192.168.254.1

  unbound:
    container_name: unbound
    image: "mvance/unbound-rpi:latest"
    hostname: unbound
    networks:
      macvlan:
        ipv4_address: 192.168.254.253
    volumes:
      - "./unbound:/opt/unbound/etc/unbound:ro"
    restart: unless-stopped
  # 192.168.254.253

  caddy:
    container_name: caddy
    hostname: caddy
    image: caddy:latest
    restart: unless-stopped
    networks:
      macvlan:
        ipv4_address: 192.168.254.3
    volumes:
      - ./caddy/Caddyfile:/etc/caddy/Caddyfile
      - /srv:/srv
      - caddy_data:/data
      - caddy_config:/config
    environment:
      - CLOUDFLARE_API_TOKEN=${CLOUDFLARE_API_TOKEN}
      - ACME_DNS=cloudflare
  # 192.168.254.3

  umami_db:
    image: postgres:17-alpine # Official image, multi-arch supports ARM64
    container_name: umami_db
    hostname: umami_db
    restart: unless-stopped
    networks:
      macvlan: # Your existing MacVlan network
        ipv4_address: 192.168.254.4 # STATIC IP for Umami DB - CHOOSE A FREE IP
    volumes:
      - umami_db_data:/var/lib/postgresql/data # Persistent storage for database
    environment:
      POSTGRES_USER: ${UMAMI_DB_USER}         # From .env file (via GitHub Secrets)
      POSTGRES_PASSWORD: ${UMAMI_DB_PASSWORD}   # From .env file (via GitHub Secrets)
      POSTGRES_DB: ${UMAMI_DB_NAME}           # From .env file (via GitHub Secrets)
    healthcheck: # Optional, but good for ensuring DB is ready before Umami app starts
      test: ["CMD-SHELL", "pg_isready -U ${UMAMI_DB_USER} -d ${UMAMI_DB_NAME}"]
      interval: 10s
      timeout: 5s
      retries: 5
  # 192.168.254.4

  umami_app:
    image: docker.umami.is/umami-software/umami:postgresql-latest # Official image, multi-arch supports ARM64
    container_name: umami_app
    hostname: umami_app
    restart: unless-stopped
    networks:
      macvlan: # Your existing MacVlan network
        ipv4_address: 192.168.254.5 # STATIC IP for Umami App - CHOOSE A FREE IP
    depends_on:
      umami_db: # Wait for DB to be healthy (if healthcheck is defined)
        condition: service_healthy
    environment:
      # Use the MacVlan IP of your umami_db container here
      DATABASE_URL: postgresql://${UMAMI_DB_USER}:${UMAMI_DB_PASSWORD}@192.168.254.4:5432/${UMAMI_DB_NAME}
      DATABASE_TYPE: postgresql
      APP_SECRET: ${UMAMI_APP_SECRET} # From .env file (via GitHub Secrets) - IMPORTANT: Must be a strong random string
      TZ: "America/New_York" # Or your preferred timezone
      DISABLE_LOGIN: "false" # Default is false, allows login to create admin. Set to true after initial setup if desired.
  # 192.168.254.5:3000 default

  # --- Monitoring Services ---

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    hostname: prometheus
    restart: unless-stopped
    volumes:
      - ./prometheus/config:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.retention.time=30d"
      - "--storage.tsdb.path=/prometheus"
      - "--web.enable-lifecycle"
    networks:
      macvlan:
        ipv4_address: 192.168.254.220
    # Prometheus UI will be on http://192.168.254.220:9090

  grafana:
    image: grafana/grafana-oss:latest
    container_name: grafana
    hostname: grafana
    restart: unless-stopped
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning/datasources:/etc/grafana/provisioning/datasources
      - ./grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - TZ="America/New_York"
    networks:
      macvlan:
        ipv4_address: 192.168.254.221
    # Grafana UI will be on http://192.168.254.221:3000

  rpi_node_exporter:
    image: prom/node-exporter:latest
    container_name: rpi_node_exporter
    hostname: rpi_node_exporter
    restart: unless-stopped
    network_mode: host
    pid: host
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - "--path.procfs=/host/proc"
      - "--path.sysfs=/host/sys"
      - "--path.rootfs=/rootfs"
      - "--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc|rootfs/var/lib/docker/containers|rootfs/var/lib/docker/overlay2|rootfs/run/docker/netns|rootfs/var/lib/docker/aufs)($$|/)"
    # Prometheus will scrape it on dockerHost:9100

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    hostname: cadvisor
    restart: unless-stopped
    # privileged: true # Uncomment if needed for full metrics, test without first
    devices:
      - /dev/kmsg:/dev/kmsg
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    networks:
      macvlan:
        ipv4_address: 192.168.254.222
    # cAdvisor UI will be on http://192.168.254.222:8080

  blackbox_exporter:
    image: prom/blackbox-exporter:latest
    container_name: blackbox
    hostname: blackbox
    restart: unless-stopped
    volumes:
      - ./blackbox/config:/config
    command:
      - "--config.file=/config/blackbox.yml"
    networks:
      macvlan:
        ipv4_address: 192.168.254.223
    # Blackbox Exporter will listen on http://192.168.254.223:9115

  uptime_kuma:
    image: louislam/uptime-kuma:latest
    container_name: uptime_kuma
    hostname: uptime_kuma
    restart: unless-stopped
    volumes:
      - uptime_kuma_data:/app/data
      - /var/run/docker.sock:/var/run/docker.sock:ro
    environment:
      - TZ="America/New_York"
    networks:
      macvlan:
        ipv4_address: 192.168.254.224
    # Uptime Kuma UI will be on http://192.168.254.224:3001
volumes:
  caddy_data:
  caddy_config:
  prometheus_data:
  grafana_data:
  uptime_kuma_data:
  umami_db_data:
networks:
  macvlan:
    name: pi0vlan
    driver: macvlan
    driver_opts:
      parent: eth0
    ipam:
      config:
        - subnet: "192.168.0.0/16"
          gateway: "192.168.0.1"
          ip_range: "192.168.254.0/24"
          aux_addresses:
            host_shim_ip: "192.168.254.254"
